{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## [1] Árboles de Decisión. Sobreajuste y ruido"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Para la realización de estas pruebas se utilizó el dataset público http://archive.ics.uci.edu/ml/datasets/Wine. Es uno de los datasets más populares (desde 2007) disponibles en \"UC Irvine Machine Learning Repository\". Cuenta con 1599 instancias de vinos tintos y 12 atributos [\"fixed acidity;\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\"]. El objetivo es utilizar el valor conocido del atributo \"quality\" para cada una de estas instancias que constituyen nuestra base de conocimiento para predecir, en función del valor de los 12 atributos antes mencionados, la clasificiación del atributo de calidad de una nueva instancia de vino tinto utilizando árboles de decisión.\n",
    "\n",
    "## Para realizar esta tarea se construyó en primera instancia un árbol de decisión sin restricciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 7.1.0, however version 7.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting sklearn\n",
      "/Library/Python/2.7/site-packages/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "  InsecurePlatformWarning\n",
      "Requirement already satisfied (use --upgrade to upgrade): scikit-learn in /Library/Python/2.7/site-packages (from sklearn)\n",
      "Installing collected packages: sklearn\n",
      "\u001b[31mException:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Python/2.7/site-packages/pip/basecommand.py\", line 223, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 299, in run\n",
      "    root=options.root_path,\n",
      "  File \"/Library/Python/2.7/site-packages/pip/req/req_set.py\", line 646, in install\n",
      "    **kwargs\n",
      "  File \"/Library/Python/2.7/site-packages/pip/req/req_install.py\", line 813, in install\n",
      "    self.move_wheel_files(self.source_dir, root=root)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/req/req_install.py\", line 1008, in move_wheel_files\n",
      "    isolated=self.isolated,\n",
      "  File \"/Library/Python/2.7/site-packages/pip/wheel.py\", line 339, in move_wheel_files\n",
      "    clobber(source, lib_dir, True)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/wheel.py\", line 310, in clobber\n",
      "    ensure_dir(destdir)\n",
      "  File \"/Library/Python/2.7/site-packages/pip/utils/__init__.py\", line 70, in ensure_dir\n",
      "    os.makedirs(path)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/os.py\", line 157, in makedirs\n",
      "    mkdir(name, mode)\n",
      "OSError: [Errno 13] Permission denied: '/Library/Python/2.7/site-packages/sklearn-0.0.dist-info'\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ef3e4ee1c1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install sklearn '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "!sudo pip install sklearn \n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the CSV file as a numpy matrix\n",
    "dataset = np.loadtxt(\"../part1/winequality-red.csv\", delimiter=\";\", skiprows=1)\n",
    "\n",
    "# separate the data from the target attributes\n",
    "X = dataset[:,0:11]\n",
    "y = dataset[:,11]\n",
    "\n",
    "# build tree without restrictions\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X,y)\n",
    "\n",
    "print(\"Node count: \" + clf.tree_.node_count)\n",
    "print(\"Score: \" + clf.score(X,y))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## El 'score' es un valor real entre '0' y '1.0' que puede utilizarce como medida de precisión con la que el árbol de decisión generado permite predecir los valores 'y' de la matriz de atributos 'X' pasados como parámetros.\n",
    "\n",
    "## En este caso puede observarse que esa medida fue '1.0' lo que significa que la precisión fue máxima. La razón por la que esto ocurre es que el árbol de decisión generado no posee ninguna restricción para su generación y se ajusta en forma perfecta a los datos que se utilizaron para su construcción (mismos datos 'X' e 'y' que fueron utilizados como parámetros de la función de precisión 'score').\n",
    "\n",
    "## Cabe destacar que, por cuestiones de dimensión, se decidió omitir el gráfico del árbol de decisión generado pero puede encontrarse en adjunto en la carpeta del informe bajo el nombre \"base_tree.dot\".\n",
    "\n",
    "## Con el objetivo de evaluar el comportamiento de la métrica de 'score' decidimos variar la construcción del árbol anterior acotando la cantidad de 'max_leaf_nodes' y se decidió graficar estos valores con el fin de poder analizarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "max_node_count = clf.tree_.node_count\n",
    "\n",
    "x_coord = []\n",
    "node_count = []\n",
    "score = []\n",
    "    \n",
    "# build different trees depending on max_leaf_nodes\n",
    "for i in range(2,1000):\n",
    "    clf = tree.DecisionTreeClassifier(max_leaf_nodes=i).fit(X,y)\n",
    "    x_coord.append(i)\n",
    "    node_count.append(clf.tree_.node_count)\n",
    "    score.append(clf.score(X,y))\n",
    "\n",
    "# generate chart 1\n",
    "plt.plot(x_coord, node_count, '')\n",
    "plt.title('Variacion de la cantidad de nodos restringiendo max_leaf_nodes')\n",
    "plt.xlabel('max_leaf_nodes')\n",
    "plt.ylabel('node_count')\n",
    "plt.legend([\"node_count\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# generate chart 2\n",
    "plt.plot(x_coord, score, '')\n",
    "plt.title('Variacion del score restringiendo max_leaf_nodes')\n",
    "plt.xlabel('max_leaf_nodes')\n",
    "plt.ylabel('score')\n",
    "plt.legend([\"score\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## En el primer gráfico se puede observar la evidente y esperable tendencia estrictamente creciente de la cantidad total de nodos de los árboles generados a medida que se aumenta el valor máximo de hojas disponibles para su construcción. Este valor pasa a ser constante ni bien la máxima cantidad de hojas posibles coincide con las del árbol original resultando en un valor total de nodos igual a 'max_node_count'.\n",
    "\n",
    "## En el segundo gráfico se puede observar que cuanto más se restringe la cantidad de hojas del árbol de decisión más baja es la precisión con la que puede predecirse los valores del vector 'y' correspondiente a la matriz de atributos 'X' aún cuando éstos son los mismos datos que se utilizaron para su construcción. El punto de estabilización del valor del 'score' en '1.0' coindide con el punto en el cuál el árbol alcanza el valor total de nodos igual a 'max_node_count'.\n",
    "\n",
    "## Ahora bien, más allá del análisis de comportamiento previamente realizado resulta interesante ver cómo se comporta la precisión de los árboles de decisión generados cuando el set de datos utilizado para su evaluación no es el mismo que el utilizado para su construcción. Con este fin realizamos una partición del dataset original en dos conjuntos que llamamos 'train' y 'test'. El primero corresponde al 70% del total de datos elegidos en forma aleatoria y será utilizado como base de conocimiento para la construcción del árbol de decisión. El segundo set contiene el resto de los datos (30% del total) y será utilizado para realizar la validación el model generado. \n",
    "\n",
    "## Para realizar esta tarea se utilizó el módulo 'cross_validation' de 'sklearn' y se iteró sobre la misma cota de construción utilizada anteriormente. Posteriormente se prodeció a graficar el valor del 'score' en función de los 'max_leaf_nodes' para ambos conjuntos de datos utilizando el árbol generado utilizando los valores del set 'train' únicamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "# split dataset: 30% for test and 70% for train\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# initialize data and file\n",
    "performanceX = []\n",
    "performance_train = []\n",
    "performance_test = []\n",
    "    \n",
    "for i in range(2,300):\n",
    "    # clf generated based on train data\n",
    "    clf = tree.DecisionTreeClassifier(max_leaf_nodes=i).fit(X_train,y_train)\n",
    "    performanceX.append(clf.tree_.node_count)\n",
    "    performance_train.append(clf.score(X_train,y_train))\n",
    "    performance_test.append(clf.score(X_test,y_test))\n",
    "    result_performance_file.write(str(clf.tree_.node_count)+\",\"+str(clf.score(X_train,y_train))+\",\"+str(clf.score(X_test,y_test))+\"\\n\")\n",
    "\n",
    "# generate chart\n",
    "plt.plot(performanceX, performance_train, '', performanceX, performance_test, '')\n",
    "plt.title('Performance con cross_validation')\n",
    "plt.xlabel('node_count')\n",
    "plt.ylabel('score')\n",
    "plt.legend([\"train\",\"test\"], loc=\"upper left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## En el gráfico presentado se puede observar que el comportamiento de la métrica de precisión respecto a los datos de entrenamiento sigue el comportamiento previamente analizado y descripto. Sin embargo, cuando se evalúa la precisión de la predicción respecto a datos nuevos (en este caso los valores del set de 'test') el comportamiento observado es radicalmente diferente. No sólo se observa que el valor máximo de 'score' alcanzado es más bajo en este caso sino que además la curva de crecimiento de este valor respecto al total de nodos no es creciente sino que deja de crecer estrictamente a partir de cierto número de nodos.\n",
    "\n",
    "## El comportamiento descripto en el párrafo anterior deja en evidencia que, si bien aumentar el tamaño del árbol permite ajustar mejor la precisión de la predicción sobre los datos de entrenamiento no necesariamente mejora la predicción sobre datos frescos y más aún hasta puede empeorarla. Esta interpretación permite analizar el fenómeno de 'sobreajuste' que suele presentarse cuando se utilizan como modelos de predicción árboles de decisión.\n",
    "\n",
    "## TODO: moraleja hayq ue encontrar el punto justo\n",
    "\n",
    "## Cabe destacar que, se eligió como cota máxima de iteración del ciclo el valor '300' ya que es el valor aproximado en el que se observó se alcanza la cantidad total de nodos en el árbol generado con esa cantidad de hojas máxima."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
